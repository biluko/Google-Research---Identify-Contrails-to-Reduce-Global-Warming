{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Summary\n","- Baseline written using Pytorch Lightning\n","- resnest26d as encoder\n","- Dataset is taken from: https://www.kaggle.com/datasets/shashwatraman/contrails-images-ash-color\n","\n","#### Improvements over [previous version](https://www.kaggle.com/code/egortrushin/gr-icrgw-pytorch-lightning-baseline-unet-resnest) (please upvote).\n","- Option to change image size\n","- Mixed precision training (only useful with T4x2, on P100 this slows down training). This helps to use GPU memory more efficiently\n","- Training using 2 GPUs - with 2 GPUs we have more memory and higher speed\n","- Other numerous small changes"]},{"cell_type":"markdown","metadata":{},"source":["/kaggle/input/google-research-identify-contrails-reduce-global-warming"]},{"cell_type":"markdown","metadata":{},"source":["### Training part"]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-29T12:51:05.316797Z","iopub.status.busy":"2023-07-29T12:51:05.316330Z","iopub.status.idle":"2023-07-29T12:51:13.040760Z","shell.execute_reply":"2023-07-29T12:51:13.039754Z","shell.execute_reply.started":"2023-07-29T12:51:05.316747Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/kaggle/working/../input/pretrained-models-pytorch/pretrainedmodels/models/dpn.py:255: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","  if block_type is 'proj':\n","/kaggle/working/../input/pretrained-models-pytorch/pretrainedmodels/models/dpn.py:258: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","  elif block_type is 'down':\n","/kaggle/working/../input/pretrained-models-pytorch/pretrainedmodels/models/dpn.py:262: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","  assert block_type is 'normal'\n"]}],"source":["import sys\n","sys.path.append(\"../input/pretrained-models-pytorch\")\n","sys.path.append(\"../input/efficientnet-pytorch\")\n","sys.path.append(\"/kaggle/input/smp-github/segmentation_models.pytorch-master\")\n","sys.path.append(\"/kaggle/input/timm-pretrained-resnest/resnest/\")\n","import segmentation_models_pytorch as smp"]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-29T12:51:13.043753Z","iopub.status.busy":"2023-07-29T12:51:13.043110Z","iopub.status.idle":"2023-07-29T12:51:17.704325Z","shell.execute_reply":"2023-07-29T12:51:17.702453Z","shell.execute_reply.started":"2023-07-29T12:51:13.043717Z"},"trusted":true},"outputs":[],"source":["!mkdir -p /root/.cache/torch/hub/checkpoints/\n","!cp /kaggle/input/timm-pretrained-resnest/resnest/gluon_resnest26-50eb607c.pth /root/.cache/torch/hub/checkpoints/gluon_resnest26-50eb607c.pth\n","!cp /kaggle/input/seresnext/se_resnext50_32x4d-a260b3a4.pth /root/.cache/torch/hub/checkpoints/se_resnext50_32x4d-a260b3a4.pth"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:51:17.706431Z","iopub.status.busy":"2023-07-29T12:51:17.706019Z","iopub.status.idle":"2023-07-29T12:51:17.715226Z","shell.execute_reply":"2023-07-29T12:51:17.714203Z","shell.execute_reply.started":"2023-07-29T12:51:17.706386Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing config.yaml\n"]}],"source":["%%writefile config.yaml\n","\n","data_path: \"/kaggle/input/contrails-images-ash-color\"\n","output_dir: \"models\"\n","\n","seed: 20\n","\n","train_bs: 48\n","valid_bs: 128\n","workers: 2\n","\n","progress_bar_refresh_rate: 1\n","\n","early_stop:\n","    monitor: \"val_loss\"\n","    mode: \"min\"\n","    patience: 999\n","    verbose: 1\n","\n","trainer:\n","    max_epochs: 30\n","    min_epochs: 30\n","    enable_progress_bar: True\n","    precision: \"16-mixed\"\n","    devices: 2\n","\n","model:\n","    seg_model: \"Unet++\"\n","    encoder_name: \"se_resnext50_32x4d\"\n","    loss_smooth: 1.0\n","    image_size: 768\n","    optimizer_params:\n","        lr: 5e-5\n","        weight_decay: 0.02\n","    scheduler:\n","        name: \"CosineAnnealingLR\"\n","        params:\n","            CosineAnnealingLR:\n","                T_max: 2\n","                eta_min: 1.0e-6\n","                last_epoch: -1\n","            ReduceLROnPlateau:\n","                mode: \"min\"\n","                factor: 0.31622776601\n","                patience: 4\n","                verbose: True"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:51:17.717374Z","iopub.status.busy":"2023-07-29T12:51:17.716795Z","iopub.status.idle":"2023-07-29T12:51:17.729545Z","shell.execute_reply":"2023-07-29T12:51:17.728535Z","shell.execute_reply.started":"2023-07-29T12:51:17.717328Z"},"trusted":true},"outputs":[],"source":["# Dataset\n","\n","import torch\n","import numpy as np\n","import torchvision.transforms as T\n","\n","class ContrailsDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, image_size=256, train=True):\n","\n","        self.df = df\n","        self.trn = train\n","        self.normalize_image = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","        self.image_size = image_size\n","        if image_size != 256:\n","            self.resize_image = T.transforms.Resize(image_size)\n","\n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        con_path = row.path\n","        con = np.load(str(con_path))\n","\n","        img = con[..., :-1]\n","        label = con[..., -1]\n","\n","        label = torch.tensor(label)\n","\n","        img = torch.tensor(np.reshape(img, (256, 256, 3))).to(torch.float32).permute(2, 0, 1)\n","\n","        if self.image_size != 256:\n","            img = self.resize_image(img)\n","\n","        img = self.normalize_image(img)\n","\n","        return img.float(), label.float()\n","\n","    def __len__(self):\n","        return len(self.df)"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-29T12:51:17.733480Z","iopub.status.busy":"2023-07-29T12:51:17.733191Z","iopub.status.idle":"2023-07-29T12:51:28.798055Z","shell.execute_reply":"2023-07-29T12:51:28.797069Z","shell.execute_reply.started":"2023-07-29T12:51:17.733457Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["# Lightning module\n","\n","import torch\n","import pytorch_lightning as pl\n","import segmentation_models_pytorch as smp\n","from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n","from torch.optim import AdamW\n","import torch.nn as nn\n","from torchmetrics.functional import dice\n","\n","seg_models = {\n","    \"Unet\": smp.Unet,\n","    \"Unet++\": smp.UnetPlusPlus,\n","    \"MAnet\": smp.MAnet,\n","    \"Linknet\": smp.Linknet,\n","    \"FPN\": smp.FPN,\n","    \"PSPNet\": smp.PSPNet,\n","    \"PAN\": smp.PAN,\n","    \"DeepLabV3\": smp.DeepLabV3,\n","    \"DeepLabV3+\": smp.DeepLabV3Plus,\n","}\n","\n","\n","class LightningModule(pl.LightningModule):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.model = model = seg_models[config[\"seg_model\"]](\n","            encoder_name=config[\"encoder_name\"],\n","            encoder_weights=\"imagenet\",\n","            in_channels=3,\n","            classes=1,\n","            activation=None,\n","            decoder_attention_type = 'scse',\n","        )\n","        self.loss_module = smp.losses.DiceLoss(mode=\"binary\", smooth=config[\"loss_smooth\"])\n","        self.val_step_outputs = []\n","        self.val_step_labels = []\n","\n","    def forward(self, batch):\n","        imgs = batch\n","        preds = self.model(imgs)\n","        return preds\n","\n","    def configure_optimizers(self):\n","        optimizer = AdamW(self.parameters(), **self.config[\"optimizer_params\"])\n","\n","        if self.config[\"scheduler\"][\"name\"] == \"CosineAnnealingLR\":\n","            scheduler = CosineAnnealingLR(\n","                optimizer,\n","                **self.config[\"scheduler\"][\"params\"][\"CosineAnnealingLR\"],\n","            )\n","            lr_scheduler_dict = {\"scheduler\": scheduler, \"interval\": \"step\"}\n","            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_dict}\n","        elif self.config[\"scheduler\"][\"name\"] == \"ReduceLROnPlateau\":\n","            scheduler = ReduceLROnPlateau(\n","                optimizer,\n","                **self.config[\"scheduler\"][\"params\"][\"ReduceLROnPlateau\"],\n","            )\n","            lr_scheduler = {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n","            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n","\n","    def training_step(self, batch, batch_idx):\n","        imgs, labels = batch\n","        preds = self.model(imgs)\n","        if self.config[\"image_size\"] != 256:\n","            preds = torch.nn.functional.interpolate(preds, size=256, mode='bilinear')\n","        loss = self.loss_module(preds, labels)\n","        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, batch_size=16)\n","\n","        for param_group in self.trainer.optimizers[0].param_groups:\n","            lr = param_group[\"lr\"]\n","        self.log(\"lr\", lr, on_step=True, on_epoch=False, prog_bar=True)\n","\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        imgs, labels = batch\n","        preds = self.model(imgs)\n","        if self.config[\"image_size\"] != 256:\n","            preds = torch.nn.functional.interpolate(preds, size=256, mode='bilinear')\n","        loss = self.loss_module(preds, labels)\n","        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n","        self.val_step_outputs.append(preds)\n","        self.val_step_labels.append(labels)\n","\n","    def on_validation_epoch_end(self):\n","        all_preds = torch.cat(self.val_step_outputs)\n","        all_labels = torch.cat(self.val_step_labels)\n","        all_preds = torch.sigmoid(all_preds)\n","        self.val_step_outputs.clear()\n","        self.val_step_labels.clear()\n","        val_dice = dice(all_preds, all_labels.long())\n","        self.log(\"val_dice\", val_dice, on_step=False, on_epoch=True, prog_bar=True)\n","        if self.trainer.global_rank == 0:\n","            print(f\"\\nEpoch: {self.current_epoch}\", flush=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:51:28.800295Z","iopub.status.busy":"2023-07-29T12:51:28.799593Z","iopub.status.idle":"2023-07-29T12:51:31.686920Z","shell.execute_reply":"2023-07-29T12:51:31.684889Z","shell.execute_reply.started":"2023-07-29T12:51:28.800266Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1\n"]},{"ename":"IndexError","evalue":"positional indexers are out-of-bounds","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1587\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3895\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3896\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3900\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3902\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3903\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:3886\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m-> 3886\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3888\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3891\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/managers.py:975\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_indices:\n\u001b[0;32m--> 975\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexers/utils.py:286\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n","\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_indices, val_indices) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kfold\u001b[38;5;241m.\u001b[39msplit(total_df)):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     train_fold \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     37\u001b[0m     valid_fold \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39miloc[val_indices]\n\u001b[1;32m     38\u001b[0m     dataset_train \u001b[38;5;241m=\u001b[39m ContrailsDataset(train_fold, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1616\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1620\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexing.py:1590\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message\u001b[39;00m\n\u001b[0;32m-> 1590\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n","\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"]}],"source":["# Actual training\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","import os\n","import torch\n","import yaml\n","import pandas as pd\n","import pytorch_lightning as pl\n","from pprint import pprint\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n","from torch.utils.data import DataLoader\n","\n","with open(\"config.yaml\", \"r\") as file_obj:\n","    config = yaml.safe_load(file_obj)\n","\n","contrails = os.path.join(config[\"data_path\"], \"contrails/\")\n","train_path = os.path.join(config[\"data_path\"], \"train_df.csv\")\n","valid_path = os.path.join(config[\"data_path\"], \"valid_df.csv\")\n","\n","train_df = pd.read_csv(train_path)\n","valid_df = pd.read_csv(valid_path)\n","\n","total_df = pd.concat([train_df, valid_df], ignore_index = True)\n","\n","from sklearn.model_selection import KFold\n","\n","n_splits = 5\n","\n","kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n","\n","for fold, (train_indices, val_indices) in enumerate(kfold.split(total_df)):\n","    print(f\"Fold {fold + 1}\")\n","    train_fold = train_df.iloc[train_indices]\n","    valid_fold = train_df.iloc[val_indices]\n","    dataset_train = ContrailsDataset(train_fold, config[\"model\"][\"image_size\"], train=True)\n","    dataset_validation = ContrailsDataset(valid_fold, config[\"model\"][\"image_size\"], train=False)\n","    data_loader_train = DataLoader(\n","        dataset_train,\n","        batch_size=config[\"train_bs\"],\n","        shuffle=True,\n","        num_workers=config[\"workers\"],\n","    )\n","    data_loader_validation = DataLoader(\n","        dataset_validation,\n","        batch_size=config[\"valid_bs\"],\n","        shuffle=False,\n","        num_workers=config[\"workers\"],\n","    )\n","    model = LightningModule(config[\"model\"])\n","    checkpoint_callback = ModelCheckpoint(\n","        monitor=\"val_dice\",\n","        dirpath=f\"models/fold_{fold + 1}\",\n","        filename=\"best_model\",\n","        save_top_k=1,\n","        mode = \"max\",\n","    )\n","    trainer = pl.Trainer(\n","        callbacks=[checkpoint_callback, early_stop_callback, progress_bar_callback],\n","        **config[\"trainer\"],\n","    )\n","    trainer.fit(model, data_loader_train, data_loader_validation)\n","    \n","trainer.fit(model, data_loader_train, data_loader_validation)"]},{"cell_type":"markdown","metadata":{},"source":["### Submission part"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:51:31.688077Z","iopub.status.idle":"2023-07-29T12:51:31.688674Z","shell.execute_reply":"2023-07-29T12:51:31.688441Z","shell.execute_reply.started":"2023-07-29T12:51:31.688418Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","data = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'\n","data_root = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/test/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:51:31.690689Z","iopub.status.idle":"2023-07-29T12:51:31.691154Z","shell.execute_reply":"2023-07-29T12:51:31.690934Z","shell.execute_reply.started":"2023-07-29T12:51:31.690913Z"},"trusted":true},"outputs":[],"source":["filenames = os.listdir(data_root)\n","test_df = pd.DataFrame(filenames, columns=['record_id'])\n","test_df['path'] = data_root + test_df['record_id'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:51:31.694892Z","iopub.status.idle":"2023-07-29T12:51:31.695384Z","shell.execute_reply":"2023-07-29T12:51:31.695146Z","shell.execute_reply.started":"2023-07-29T12:51:31.695123Z"},"trusted":true},"outputs":[],"source":["class ContrailsDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, image_size=256, train=True):\n","        \n","        self.df = df\n","        self.trn = train\n","        self.df_idx: pd.DataFrame = pd.DataFrame({'idx': os.listdir(f'/kaggle/input/google-research-identify-contrails-reduce-global-warming/test')})\n","        self.normalize_image = T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","        self.image_size = image_size\n","        if image_size != 256:\n","            self.resize_image = T.transforms.Resize(image_size)\n","    \n","    def read_record(self, directory):\n","        record_data = {}\n","        for x in [\n","            \"band_11\", \n","            \"band_14\", \n","            \"band_15\"\n","        ]:\n","\n","            record_data[x] = np.load(os.path.join(directory, x + \".npy\"))\n","\n","        return record_data\n","\n","    def normalize_range(self, data, bounds):\n","        \"\"\"Maps data to the range [0, 1].\"\"\"\n","        return (data - bounds[0]) / (bounds[1] - bounds[0])\n","    \n","    def get_false_color(self, record_data):\n","        _T11_BOUNDS = (243, 303)\n","        _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n","        _TDIFF_BOUNDS = (-4, 2)\n","        \n","        N_TIMES_BEFORE = 4\n","\n","        r = self.normalize_range(record_data[\"band_15\"] - record_data[\"band_14\"], _TDIFF_BOUNDS)\n","        g = self.normalize_range(record_data[\"band_14\"] - record_data[\"band_11\"], _CLOUD_TOP_TDIFF_BOUNDS)\n","        b = self.normalize_range(record_data[\"band_14\"], _T11_BOUNDS)\n","        false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n","        img = false_color[..., N_TIMES_BEFORE]\n","\n","        return img\n","    \n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        con_path = row.path\n","        data = self.read_record(con_path)    \n","        \n","        img = self.get_false_color(data)\n","        \n","        img = torch.tensor(np.reshape(img, (256, 256, 3))).to(torch.float32).permute(2, 0, 1)\n","        \n","        if self.image_size != 256:\n","            img = self.resize_image(img)\n","        \n","        img = self.normalize_image(img)\n","        \n","        image_id = int(self.df_idx.iloc[index]['idx'])\n","            \n","        return img.float(), torch.tensor(image_id)\n","    \n","    def __len__(self):\n","        return len(self.df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:51:31.697049Z","iopub.status.idle":"2023-07-29T12:51:31.698045Z","shell.execute_reply":"2023-07-29T12:51:31.697820Z","shell.execute_reply.started":"2023-07-29T12:51:31.697797Z"},"trusted":true},"outputs":[],"source":["test_ds = ContrailsDataset(\n","        test_df,\n","        config[\"model\"][\"image_size\"],\n","        train = False\n","    )\n"," \n","test_dl = DataLoader(test_ds, batch_size=batch_size, num_workers = 1)\n","class LightningModule(pl.LightningModule):\n","\n","    def __init__(self):\n","        super().__init__()\n","        self.model = smp.Unet(encoder_name=\"timm-resnest26d\",\n","                              encoder_weights=None,\n","                              in_channels=3,\n","                              classes=1,\n","                              activation=None,\n","                              )\n","\n","    def forward(self, batch):\n","        return self.model(batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:51:31.699476Z","iopub.status.idle":"2023-07-29T12:51:31.700440Z","shell.execute_reply":"2023-07-29T12:51:31.700181Z","shell.execute_reply.started":"2023-07-29T12:51:31.700152Z"},"trusted":true},"outputs":[],"source":["def rle_encode(x, fg_val=1):\n","    \"\"\"\n","    Args:\n","        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n","    Returns: run length encoding as list\n","    \"\"\"\n","\n","    dots = np.where(\n","        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n","    run_lengths = []\n","    prev = -2\n","    for b in dots:\n","        if b > prev + 1:\n","            run_lengths.extend((b + 1, 0))\n","        run_lengths[-1] += 1\n","        prev = b\n","    return run_lengths\n","\n","def list_to_string(x):\n","    \"\"\"\n","    Converts list to a string representation\n","    Empty list returns '-'\n","    \"\"\"\n","    if x: # non-empty list\n","        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n","    else:\n","        s = '-'\n","    return s"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:51:31.701940Z","iopub.status.idle":"2023-07-29T12:51:31.702441Z","shell.execute_reply":"2023-07-29T12:51:31.702194Z","shell.execute_reply.started":"2023-07-29T12:51:31.702171Z"},"trusted":true},"outputs":[],"source":["submission = pd.read_csv('/kaggle/input/google-research-identify-contrails-reduce-global-warming/sample_submission.csv', index_col='record_id')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:51:31.704097Z","iopub.status.idle":"2023-07-29T12:51:31.704568Z","shell.execute_reply":"2023-07-29T12:51:31.704335Z","shell.execute_reply.started":"2023-07-29T12:51:31.704315Z"},"trusted":true},"outputs":[],"source":["n_splits = 5\n","predictions = []\n","for fold in range(n_splits):\n","    print(f\"Fold {fold + 1}\")\n","    model = LightningModule.load_from_checkpoint(f\"models/fold_{fold + 1}/best_model.ckpt\")\n","    model.to(device)\n","    model.eval()\n","    fold_predictions = []\n","    for _, data in enumerate(test_dl):\n","        images, image_id = data\n","        images = images.to(device)\n","        with torch.no_grad():\n","            outputs = model(images)\n","            if config[\"model\"][\"image_size\"] != 256:\n","                outputs = torch.nn.functional.interpolate(predicted_mask, size=256, mode='bilinear')\n","            predicted_mask = torch.sigmoid(outputs).cpu().detach().numpy()\n","            fold_predictions.append(predicted_mask)\n","    predictions.append(np.concatenate(fold_predictions))\n","    \n","average_predictions = np.mean(predictions)\n","predictions_with_threshold = np.zeros((average_predictions.shape[0], 256, 256))\n","predictions_with_threshold[average_predictions[:, 0, :, :] < 0.5] = 0\n","predictions_with_threshold[average_predictions[:, 0, :, :] > 0.5] = 1\n","\n","for img_num in range(predictions_with_threshold.shape[0]):\n","    current_mask = predictions_with_threshold[img_num, :, :]\n","    current_image_id = image_id[img_num].item()\n","    submission.loc[int(current_image_id), 'encoded_pixels'] = list_to_string(rle_encode(current_mask))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:51:31.706293Z","iopub.status.idle":"2023-07-29T12:51:31.706777Z","shell.execute_reply":"2023-07-29T12:51:31.706570Z","shell.execute_reply.started":"2023-07-29T12:51:31.706548Z"},"trusted":true},"outputs":[],"source":["submission"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:51:31.708130Z","iopub.status.idle":"2023-07-29T12:51:31.709719Z","shell.execute_reply":"2023-07-29T12:51:31.709460Z","shell.execute_reply.started":"2023-07-29T12:51:31.709433Z"},"trusted":true},"outputs":[],"source":["submission.to_csv('submission.csv')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
